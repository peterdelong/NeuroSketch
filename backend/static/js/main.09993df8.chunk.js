(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{15:function(e){e.exports={activation:{elu:"",exponential:"",hard_sigmoid:"",linear:"",relu:"",selu:"",sigmoid:"",softmax:"",softplus:"",softsign:"",tanh:""},boolean:{true:"",false:""},channels_last:{channels_last:"",channels_first:""},constraint:{max_norm:"",maxnorm:"",min_max_norm:"",non_neg:"",nonneg:"",unit_norm:"",unitnorm:""},initializer:{constant:"",glorot_normal:"",glorot_uniform:"",he_normal:"",he_uniform:"",identity:"",lecun_normal:"",lecun_uniform:"",ones:"",orthogonal:"",random_normal:"",random_uniform:"",truncated_normal:"",uniform:"",zeros:""},"one of valid or same":{same:"",valid:""},"one of valid, causal or same":{causal:"",same:"",valid:""},"one of {'sum', 'mul', 'concat', 'ave', None}":{sum:"",mul:"",concat:"",ave:"",None:""},"one of nearest or bilinear":{nearest:"",bilinear:""},regularizer:{l1:"",l1_l2:"",l2:""},"data type":{int8:"",int16:"",int32:"",int64:"",uint8:"",uint16:"",uint32:"",uint64:"",float16:"",float32:"",float64:""},dtype:{int8:"",int16:"",int32:"",int64:"",uint8:"",uint16:"",uint32:"",uint64:"",float16:"",float32:"",float64:""}}},24:function(e){e.exports={Activation:{activation:""},ActivityRegularization:{l1:"0.0",l2:"0.0"},Add:{},AlphaDropout:{noise_shape:"None",rate:"",seed:"None"},Average:{},AveragePooling1D:{data_format:"channels_last",padding:"valid",pool_size:"2",strides:"None"},AveragePooling2D:{data_format:"None",padding:"valid",pool_size:"(2, 2)",strides:"None"},AveragePooling3D:{data_format:"None",padding:"valid",pool_size:"(2, 2, 2)",strides:"None"},BatchNormalization:{axis:"-1",beta_constraint:"None",beta_initializer:"zeros",beta_regularizer:"None",center:"True",epsilon:"0.001",gamma_constraint:"None",gamma_initializer:"ones",gamma_regularizer:"None",momentum:"0.99",moving_mean_initializer:"zeros",moving_variance_initializer:"ones",scale:"True"},Bidirectional:{layer:"",merge_mode:"concat",weights:"None"},Concatenate:{axis:"-1"},Conv1D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"channels_last",dilation_rate:"1",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",padding:"valid",strides:"1",use_bias:"True"},Conv2D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",dilation_rate:"(1, 1)",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",padding:"valid",strides:"(1, 1)",use_bias:"True"},Conv2DTranspose:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",dilation_rate:"(1, 1)",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",output_padding:"None",padding:"valid",strides:"(1, 1)",use_bias:"True"},Conv3D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",dilation_rate:"(1, 1, 1)",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",padding:"valid",strides:"(1, 1, 1)",use_bias:"True"},Conv3DTranspose:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",output_padding:"None",padding:"valid",strides:"(1, 1, 1)",use_bias:"True"},ConvLSTM2D:{kernel_size:"",activation:"tanh",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",dilation_rate:"(1, 1)",dropout:"0.0",filters:"",go_backwards:"False",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",padding:"valid",recurrent_activation:"hard_sigmoid",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",return_sequences:"False",stateful:"False",strides:"(1, 1)",unit_forget_bias:"True",use_bias:"True"},Cropping1D:{cropping:"(1, 1)"},Cropping2D:{"(0, 0))":"",cropping:"((0, 0)",data_format:"None"},Cropping3D:{"(1, 1)":"","(1, 1))":"",cropping:"((1, 1)",data_format:"None"},CuDNNGRU:{activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_constraint:"None",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",return_sequences:"False",return_state:"False",stateful:"False",units:""},CuDNNLSTM:{activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_constraint:"None",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",return_sequences:"False",return_state:"False",stateful:"False",unit_forget_bias:"True",units:""},Dense:{activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",units:"",use_bias:"True"},DepthwiseConv2D:{activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",depth_multiplier:"1",depthwise_constraint:"None",depthwise_initializer:"glorot_uniform",depthwise_regularizer:"None",kernel_size:"",padding:"valid",strides:"(1, 1)",use_bias:"True"},Dot:{axes:"",normalize:"False"},Dropout:{noise_shape:"None",rate:"",seed:"None"},ELU:{alpha:"1.0"},Embedding:{output_dim:"",activity_regularizer:"None",embeddings_constraint:"None",embeddings_initializer:"uniform",embeddings_regularizer:"None",input_dim:"",input_length:"None",mask_zero:"False"},Flatten:{data_format:"None"},GRU:{activation:"tanh",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",dropout:"0.0",go_backwards:"False",implementation:"1",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_activation:"hard_sigmoid",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",reset_after:"False",return_sequences:"False",return_state:"False",stateful:"False",units:"",unroll:"False",use_bias:"True"},GRUCell:{activation:"tanh",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",dropout:"0.0",implementation:"1",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_activation:"hard_sigmoid",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",reset_after:"False",units:"",use_bias:"True"},GaussianDropout:{rate:""},GaussianNoise:{stddev:""},GlobalAveragePooling1D:{data_format:"channels_last"},GlobalAveragePooling2D:{data_format:"None"},GlobalAveragePooling3D:{data_format:"None"},GlobalMaxPooling1D:{data_format:"channels_last"},GlobalMaxPooling2D:{data_format:"None"},GlobalMaxPooling3D:{data_format:"None"},Input:{batch_shape:"None",dtype:"",name:"None",shape:"",sparse:"False",tensor:"None"},LSTM:{activation:"tanh",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",dropout:"0.0",go_backwards:"False",implementation:"1",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_activation:"hard_sigmoid",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",return_sequences:"False",return_state:"False",stateful:"False",unit_forget_bias:"True",units:"",unroll:"False",use_bias:"True"},LSTMCell:{activation:"tanh",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",dropout:"0.0",implementation:"1",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_activation:"hard_sigmoid",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",unit_forget_bias:"True",units:"",use_bias:"True"},Lambda:{arguments:"None",function:"",mask:"None",output_shape:"None"},LeakyReLU:{alpha:"0.3"},LocallyConnected1D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",padding:"valid",strides:"1",use_bias:"True"},LocallyConnected2D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",filters:"",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",padding:"valid",strides:"(1, 1)",use_bias:"True"},Masking:{mask_value:"0.0"},MaxPooling1D:{data_format:"channels_last",padding:"valid",pool_size:"2",strides:"None"},MaxPooling2D:{data_format:"None",padding:"valid",pool_size:"(2, 2)",strides:"None"},MaxPooling3D:{data_format:"None",padding:"valid",pool_size:"(2, 2, 2)",strides:"None"},Maximum:{},Multiply:{},PReLU:{alpha_constraint:"None",alpha_initializer:"zeros",alpha_regularizer:"None",shared_axes:"None"},Permute:{dims:""},RNN:{cell:"",go_backwards:"False",return_sequences:"False",return_state:"False",stateful:"False",unroll:"False"},ReLU:{max_value:"None",negative_slope:"0.0",threshold:"0.0"},RepeatVector:{n:""},Reshape:{target_shape:""},SeparableConv1D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"channels_last",depth_multiplier:"1",depthwise_constraint:"None",depthwise_initializer:"glorot_uniform",depthwise_regularizer:"None",dilation_rate:"1",filters:"",padding:"valid",pointwise_constraint:"None",pointwise_initializer:"glorot_uniform",pointwise_regularizer:"None",strides:"1",use_bias:"True"},SeparableConv2D:{kernel_size:"",activation:"None",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",data_format:"None",depth_multiplier:"1",depthwise_constraint:"None",depthwise_initializer:"glorot_uniform",depthwise_regularizer:"None",dilation_rate:"(1, 1)",filters:"",padding:"valid",pointwise_constraint:"None",pointwise_initializer:"glorot_uniform",pointwise_regularizer:"None",strides:"(1, 1)",use_bias:"True"},SimpleRNN:{activation:"tanh",activity_regularizer:"None",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",dropout:"0.0",go_backwards:"False",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",return_sequences:"False",return_state:"False",stateful:"False",units:"",unroll:"False",use_bias:"True"},SimpleRNNCell:{activation:"tanh",bias_constraint:"None",bias_initializer:"zeros",bias_regularizer:"None",dropout:"0.0",kernel_constraint:"None",kernel_initializer:"glorot_uniform",kernel_regularizer:"None",recurrent_constraint:"None",recurrent_dropout:"0.0",recurrent_initializer:"orthogonal",recurrent_regularizer:"None",units:"",use_bias:"True"},Softmax:{axis:"-1"},SpatialDropout1D:{rate:""},SpatialDropout2D:{data_format:"None",rate:""},SpatialDropout3D:{data_format:"None",rate:""},Subtract:{},ThresholdedReLU:{theta:"1.0"},TimeDistributed:{layer:""},UpSampling1D:{size:"2"},UpSampling2D:{data_format:"None",interpolation:"nearest",size:"(2, 2)"},UpSampling3D:{data_format:"None",size:"(2, 2, 2)"},ZeroPadding1D:{padding:"1"},ZeroPadding2D:{data_format:"None",padding:"(1, 1)"},ZeroPadding3D:{data_format:"None",padding:"(1, 1, 1)"},add:{inputs:""},average:{inputs:""},concatenate:{axis:"-1",inputs:""},dot:{axes:"",inputs:"",normalize:"False"},maximum:{inputs:""},multiply:{inputs:""},subtract:{inputs:""}}},25:function(e){e.exports={Activation:{activation:"name of activation function to use, or alternatively, a Theano or TensorFlow operation."},ActivityRegularization:{l1:"L1 regularization factor (positive float).",l2:"L2 regularization factor (positive float)."},AlphaDropout:{rate:"float, drop probability (as with Dropout). The multiplicative noise will have standard deviation sqrt(rate / (1 - rate)).",seed:"A Python integer to use as random seed."},AveragePooling1D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps).",padding:"One of valid or same (case-insensitive).",pool_size:"Integer, size of the average pooling windows.",strides:"Integer, or None.Factor by which to downscale. E.g.2 will halve the input. If None, it will default to pool_size."},AveragePooling2D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",padding:"One of valid or same (case-insensitive).",pool_size:"integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.",strides:"Integer, tuple of 2 integers, or None. Strides values. If None, it will default to pool_size."},AveragePooling3D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",padding:"One of valid or same (case-insensitive).",pool_size:"tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.",strides:"tuple of 3 integers, or None.Strides values."},BatchNormalization:{axis:"Integer, the axis that should be normalized (typically the features axis). For instance, after a Conv2D layer with data_format= channels_first , set axis=1 in BatchNormalization.",beta_constraint:"Optional constraint for the beta weight.",beta_initializer:"Initializer for the beta weight.",beta_regularizer:"Optional regularizer for the beta weight.",center:"If True, add offset of beta to normalized tensor. If False, beta is ignored.",epsilon:"Small float added to variance to avoid dividing by zero.",gamma_constraint:"Optional constraint for the gamma weight.",gamma_initializer:"Initializer for the gamma weight.",gamma_regularizer:"Optional regularizer for the gamma weight.",momentum:"Momentum for the moving mean and the moving variance.",moving_mean_initializer:"Initializer for the moving mean.",moving_variance_initializer:"Initializer for the moving variance.",scale:"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g.nn.relu), this can be disabled since the scaling will be done by the next layer."},Bidirectional:{layer:"Recurrent instance.",merge_mode:"Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list."},Concatenate:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (at least 2)."},Conv1D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last (default) or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, steps, channels) (default format for temporal data in Keras) while channels_first corresponds to inputs with shape (batch, channels, steps).",dilation_rate:"an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.",padding:"One of valid, causal or same (case-insensitive).  valid means no padding .  same results in padding the input such that the output has the same length as the original input.  causal results in causal (dilated) convolutions, e.g.output[t] does not depend on input[t + 1:]. A zero padding is used such that the output has the same length as the original input. Useful when modeling temporal data where the model should not violate the temporal order.See <a href= https://arxiv.org/abs/1609.03499 >WaveNet: A Generative Model for Raw Audio, section 2.1</a>.",strides:"An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},Conv2D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",dilation_rate:"an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",padding:"one of valid or same (case-insensitive). Note that same is slightly inconsistent across backends with strides != 1, as described <a href= https://github.com/keras-team/keras/pull/9473#issuecomment-372166860 >here</a>",strides:"An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},Conv2DTranspose:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",dilation_rate:"an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",output_padding:"An integer or tuple/list of 2 integers, specifying the amount of padding along the height and width of the output tensor. Can be a single integer to specify the same value for all spatial dimensions. The amount of output padding along a given dimension must be lower than the stride along that same dimension. If set to None (default), the output shape is inferred.",padding:"one of valid or same (case-insensitive).",strides:"An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},Conv3D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",dilation_rate:"an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.",filters:"Integer, the dimensionality of the output space (i.e. then number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",padding:"one of valid or same (case-insensitive).",strides:"An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},Conv3DTranspose:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, depth, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, depth, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",dilation_rate:"an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",output_padding:"An integer or tuple/list of 3 integers, specifying the amount of padding along the depth, height, and width. Can be a single integer to specify the same value for all spatial dimensions. The amount of output padding along a given dimension must be lower than the stride along that same dimension. If set to None (default), the output shape is inferred.",padding:"one of valid or same (case-insensitive).",strides:"An integer or tuple/list of 3 integers, specifying the strides of the convolution along the depth, height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},ConvLSTM2D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last (default) or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, time, ..., channels) while channels_first corresponds to inputs with shape (batch, time, channels, ...). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",dilation_rate:"An integer or tuple/list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",filters:"Integer, the dimensionality of the output space (i.e. the number output of filters in the convolution).",go_backwards:"Boolean (default False). If True, process the input sequence backwards.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of n integers, specifying the dimensions of the convolution window.",padding:"One of valid or same (case-insensitive).",recurrent_activation:"Activation function to use for the recurrent step.",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",return_sequences:"Boolean.Whether to return the last output in the output sequence, or the full sequence.",stateful:"Boolean (default False).If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.",strides:"An integer or tuple/list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",unit_forget_bias:"Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with bias_initializer= zeros . This is recommended in <a href= http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf >Jozefowicz et al.(2015)</a>.",use_bias:"Boolean, whether the layer uses a bias vector."},Cropping1D:{cropping:"int or tuple of int (length 2) How many units should be trimmed off at the beginning and end of the cropping dimension (axis 1). If a single int is provided, the same value will be used for both."},Cropping2D:{cropping:"int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.<ul>\n<li>If int: the same symmetric cropping is applied to height and width.\n<li>If tuple of 2 ints: interpreted as two different symmetric cropping values for height and width: (symmetric_height_crop, symmetric_width_crop).\n<li>If tuple of 2 tuples of 2 ints: interpreted as ((top_crop, bottom_crop), (left_crop, right_crop))\n</ul>\n",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},Cropping3D:{cropping:"int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.<ul>\n<li>If int: the same symmetric cropping is applied to depth, height, and width.\n<li>If tuple of 3 ints: interpreted as two different symmetric cropping values for depth, height, and width: (symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop).\n<li>If tuple of 3 tuples of 2 ints: interpreted as ((left_dim1_crop, right_dim1_crop),   (left_dim2_crop, right_dim2_crop),   (left_dim3_crop, right_dim3_crop))\n</ul>\n",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},CuDNNGRU:{units:" Positive integer, dimensionality of the output space.",kernel_initializer:" Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",recurrent_initializer:" Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",bias_initializer:" Initializer for the bias vector.",kernel_regularizer:" Regularizer function applied to the kernel weights matrix.",recurrent_regularizer:" Regularizer function applied to the recurrent_kernel weights matrix.",bias_regularizer:" Regularizer function applied to the bias vector.",activity_regularizer:" Regularizer function applied to the output of the layer (its activation).",kernel_constraint:" Constraint function applied to the kernel weights matrix.",recurrent_constraint:" Constraint function applied to the recurrent_kernel weights matrix.",bias_constraint:" Constraint function applied to the bias vector.",return_sequences:" Boolean. Whether to return the last output. in the output sequence, or the full sequence.",return_state:" Boolean. Whether to return the last state in addition to the output.",stateful:" Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch."},CuDNNLSTM:{units:" Positive integer, dimensionality of the output space.",kernel_initializer:" Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",unit_forget_bias:" Boolean. If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=zeros. This is recommended in Jozefowicz et al. (2015).",recurrent_initializer:" Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",bias_initializer:" Initializer for the bias vector.",kernel_regularizer:" Regularizer function applied to the kernel weights matrix.",recurrent_regularizer:" Regularizer function applied to the recurrent_kernel weights matrix.",bias_regularizer:" Regularizer function applied to the bias vector.",activity_regularizer:" Regularizer function applied to the output of the layer (its activation).",kernel_constraint:" Constraint function applied to the kernel weights matrix.",recurrent_constraint:" Constraint function applied to the recurrent_kernel weights matrix.",bias_constraint:" Constraint function applied to the bias vector.",return_sequences:" Boolean. Whether to return the last output. in the output sequence, or the full sequence.",return_state:" Boolean. Whether to return the last state in addition to the output.",stateful:" Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch."},Dense:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",units:"Positive integer, dimensionality of the output space.",use_bias:"Boolean, whether the layer uses a bias vector."},DepthwiseConv2D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie.'linear' activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its 'activation').",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be 'channels_last'.",depth_multiplier:"The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.",depthwise_constraint:"Constraint function applied to the depthwise kernel matrix.",depthwise_initializer:"Initializer for the depthwise kernel matrix.",depthwise_regularizer:"Regularizer function applied to the depthwise kernel matrix.",kernel_size:"An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",padding:"one of valid or same (case-insensitive).",strides:"An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},Dot:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (at least 2)."},Dropout:{noise_shape:"1D integer tensor representing the shape of the binary dropout mask that will be multiplied with the input. For instance, if your inputs have shape (batch_size, timesteps, features) and you want the dropout mask to be the same for all timesteps, you can use noise_shape=(batch_size, 1, features).",rate:"float between 0 and 1.Fraction of the input units to drop.",seed:"A Python integer to use as random seed."},ELU:{alpha:"scale for the negative factor."},Embedding:{embeddings_constraint:"Constraint function applied to the embeddings matrix.",embeddings_initializer:"Initializer for the embeddings matrix.",embeddings_regularizer:"Regularizer function applied to the embeddings matrix.",input_dim:"int &gt; 0.Size of the vocabulary, i.e.maximum integer index + 1.",input_length:"Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).",mask_zero:"Whether or not the input value 0 is a special padding value that should be masked out. This is useful when using <a href= ../recurrent/ >recurrent layers</a> which may take variable length input. If this is True then all subsequent layers in the model need to support masking or an exception will be raised. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).",output_dim:"int &gt;= 0.Dimension of the dense embedding."},Flatten:{data_format:"The ordering of the dimensions in the inputs. The purpose of this argument is to preserve weight ordering when switching a model from one data format to another. channels_last corresponds to inputs with shape (batch, ..., channels) while channels_first corresponds to inputs with shape (batch, channels, ...). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},GRU:{activation:"Activation function to use. Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",go_backwards:"Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.",implementation:"Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations.These modes will have different performance profiles on different hardware and for different applications.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",recurrent_activation:"Activation function to use for the recurrent step. Default: hard sigmoid (hard_sigmoid). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",reset_after:"GRU convention (whether to apply reset gate after or before matrix multiplication).False =  before (default), True =  after (CuDNN compatible).",return_sequences:"Boolean.Whether to return the last output in the output sequence, or the full sequence.",return_state:"Boolean.Whether to return the last state in addition to the output.",stateful:"Boolean (default False).If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.",units:"Positive integer, dimensionality of the output space.",unroll:"Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.",use_bias:"Boolean, whether the layer uses a bias vector."},GRUCell:{recurrent_activation:"Activation function to use for the recurrent step. Default: hard sigmoid (hard_sigmoid). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",use_bias:"Boolean, whether the layer uses a bias vector.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",bias_initializer:"Initializer for the bias vector.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",bias_regularizer:"Regularizer function applied to the bias vector.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",bias_constraint:"Constraint function applied to the bias vector.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.",implementation:"Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations. These modes will have different performance profiles on different hardware and for different applications.",reset_after:"GRU convention (whether to apply reset gate after or before matrix multiplication). False = before(default), True = after (CuDNN compatible)."},GaussianDropout:{rate:"float, drop probability (as with Dropout). The multiplicative noise will have standard deviation sqrt(rate / (1 - rate))."},GaussianNoise:{stddev:"float, standard deviation of the noise distribution."},GlobalAveragePooling1D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps)."},GlobalAveragePooling2D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},GlobalAveragePooling3D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},GlobalMaxPooling1D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps)."},GlobalMaxPooling2D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},GlobalMaxPooling3D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last ."},Input:{batch_shape:"A shape tuple (integer), including the batch size. For instance, batch_shape=(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_shape=(None, 32) indicates batches of an arbitrary number of 32-dimensional vectors.",dtype:"The data type expected by the input, as a string (float32, float64, int32...)",name:"An optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn't provided.",shape:"A shape tuple (integer), not including the batch size. For instance, shape=(32,) indicates that the expected input will be batches of 32-dimensional vectors.",sparse:"A boolean specifying whether the placeholder to be created is sparse.",tensor:"Optional existing tensor to wrap into the Input layer. If set, the layer will not create a placeholder tensor."},LSTM:{activation:"Activation function to use. Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",go_backwards:"Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.",implementation:"Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations.These modes will have different performance profiles on different hardware and for different applications.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",recurrent_activation:"Activation function to use for the recurrent step. Default: hard sigmoid (hard_sigmoid). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",return_sequences:"Boolean.Whether to return the last output in the output sequence, or the full sequence.",return_state:"Boolean.Whether to return the last state in addition to the output.",stateful:"Boolean (default False).If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.",unit_forget_bias:"Boolean. If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer= zeros . This is recommended in <a href= http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf >Jozefowicz et al.(2015)</a>.",units:"Positive integer, dimensionality of the output space.",unroll:"Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.",use_bias:"Boolean, whether the layer uses a bias vector."},LSTMCell:{units:"Positive integer, dimensionality of the output space.",activation:"Activation function to use. Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",recurrent_activation:"Activation function to use for the recurrent step. Default: hard sigmoid (hard_sigmoid). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",use_bias:"Boolean, whether the layer uses a bias vector.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",bias_initializer:"Initializer for the bias vector.",unit_forget_bias:"Boolean. If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=zeros. This is recommended in Jozefowicz et al. (2015).",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",bias_regularizer:"Regularizer function applied to the bias vector.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",bias_constraint:"Constraint function applied to the bias vector.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.",implementation:"Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations. These modes will have different performance profiles on different hardware and for different applications."},Lambda:{arguments:"optional dictionary of keyword arguments to be passed to the function.",function:"The function to be evaluated. Takes input tensor or list of tensors as first argument.",mask:"",output_shape:"Expected output shape from function. Only relevant when using Theano. Can be a tuple or function. If a tuple, it only specifies the first dimension onward;      sample dimension is assumed either the same as the input:      output_shape = (input_shape[0],) + output_shape      or, the input is None and      the sample dimension is also None:      output_shape = (None,) + output_shape If a function, it specifies the entire shape as a function of the input shape: output_shape = f(input_shape)"},LeakyReLU:{alpha:"float &gt;= 0.Negative slope coefficient."},LocallyConnected1D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.",padding:"Currently only supports valid (case-insensitive).  same may be supported in the future.",strides:"An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},LocallyConnected2D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_constraint:"Constraint function applied to the kernel matrix.",kernel_initializer:"Initializer for the kernel weights matrix.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",kernel_size:"An integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",padding:"Currently only support valid (case-insensitive).  same will be supported in future.",strides:"An integer or tuple/list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions.",use_bias:"Boolean, whether the layer uses a bias vector."},Masking:{mask_value:"If all values in the input tensor at that timestep are equal to mask_value, then the timestep will be masked",input_shape:"Expected input shape into function."},MaxPooling1D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps).",padding:"One of valid or same (case-insensitive).",pool_size:"Integer, size of the max pooling windows.",strides:"Integer, or None.Factor by which to downscale. E.g.2 will halve the input. If None, it will default to pool_size."},MaxPooling2D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",padding:"One of valid or same (case-insensitive).",pool_size:"integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.",strides:"Integer, tuple of 2 integers, or None. Strides values. If None, it will default to pool_size."},MaxPooling3D:{data_format:"The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",padding:"One of valid or same (case-insensitive).",pool_size:"tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.",strides:"tuple of 3 integers, or None.Strides values."},PReLU:{alpha_constraint:"constraint for the weights.",alpha_initializer:"initializer function for the weights.",alpha_regularizer:"regularizer for the weights.",shared_axes:"the axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set shared_axes=[1, 2]."},Permute:{dims:"Tuple of integers.Permutation pattern, does not include the samples dimension.Indexing starts at 1. For instance, (2, 1) permutes the first and second dimension of the input."},ReLU:{max_value:"float >= 0.Maximum activation value.negative_slope: float >= 0.Negative slope coefficient.threshold: float.Threshold value for thresholded activation."},RNN:{cell:"A RNN cell instance.A RNN cell is a class that has:</p>\n<ul>\n<li>a call(input_at_t, states_at_t) method, returning (output_at_t, states_at_t_plus_1).The call method of the cell can also take the optional argument constants, see section Note on passing external constants below.\n<li>a state_size attribute.This can be a single integer (single state) in which case it is the size of the recurrent state (which should be the same as the size of the cell output). This can also be a list/tuple of integers (one size per state).\n<li>a output_size attribute.This can be a single integer or a TensorShape, which represent the shape of the output.For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the state_size.\n</ul>\n<p>It is also possible for cell to be a list of RNN cell instances,\nin which cases the cells get stacked on after the other in the RNN,\nimplementing an efficient stacked RNN.</p>\n",go_backwards:"Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.",input_dim:"dimensionality of the input (integer). This argument (or alternatively, the keyword argument input_shape) is required when using this layer as the first layer in a model.",input_length:"Length of input sequences, to be specified when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed). Note that if the recurrent layer is not the first layer in your model, you would need to specify the input length at the level of the first layer (e.g.via the input_shape argument)",return_sequences:"Boolean.Whether to return the last output in the output sequence, or the full sequence.</p>\n",return_state:"Boolean.Whether to return the last state in addition to the output.",stateful:"Boolean (default False).If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.",unroll:"Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences."},RepeatVector:{n:"integer, repetition factor."},Reshape:{target_shape:"target shape.Tuple of integers. Does not include the batch axis."},SeparableConv1D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, steps, channels) while channels_first corresponds to inputs with shape (batch, channels, steps).",depth_multiplier:"The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.",depthwise_constraint:"Constraint function applied to the depthwise kernel matrix.",depthwise_initializer:"Initializer for the depthwise kernel matrix.",depthwise_regularizer:"Regularizer function applied to the depthwise kernel matrix.",dilation_rate:"An integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_size:"An integer or tuple/list of single integer, specifying the length of the 1D convolution window.",padding:"one of valid or same (case-insensitive).",pointwise_constraint:"Constraint function applied to the pointwise kernel matrix.",pointwise_initializer:"Initializer for the pointwise kernel matrix.",pointwise_regularizer:"Regularizer function applied to the pointwise kernel matrix.",strides:"An integer or tuple/list of single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},SeparableConv2D:{activation:"Activation function to use. If you don't specify anything, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",depth_multiplier:"The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.",depthwise_constraint:"Constraint function applied to the depthwise kernel matrix.",depthwise_initializer:"Initializer for the depthwise kernel matrix.",depthwise_regularizer:"Regularizer function applied to the depthwise kernel matrix.",dilation_rate:"An integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.",filters:"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",kernel_size:"An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",padding:"one of valid or same (case-insensitive).",pointwise_constraint:"Constraint function applied to the pointwise kernel matrix.",pointwise_initializer:"Initializer for the pointwise kernel matrix.",pointwise_regularizer:"Regularizer function applied to the pointwise kernel matrix.",strides:"An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.",use_bias:"Boolean, whether the layer uses a bias vector."},SimpleRNN:{activation:"Activation function to use. Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",activity_regularizer:"Regularizer function applied to the output of the layer (its activation).",bias_constraint:"Constraint function applied to the bias vector.",bias_initializer:"Initializer for the bias vector.",bias_regularizer:"Regularizer function applied to the bias vector.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",go_backwards:"Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.",implementation:"Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations.These modes will have different performance profiles on different hardware and for different applications.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",recurrent_activation:"Activation function to use for the recurrent step. Default: hard sigmoid (hard_sigmoid). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",reset_after:"GRU convention (whether to apply reset gate after or before matrix multiplication).False =  before (default), True =  after (CuDNN compatible).",return_sequences:"Boolean.Whether to return the last output in the output sequence, or the full sequence.",return_state:"Boolean.Whether to return the last state in addition to the output.",stateful:"Boolean (default False).If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.",units:"Positive integer, dimensionality of the output space.",unroll:"Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.",use_bias:"Boolean, whether the layer uses a bias vector."},SimpleRNNCell:{units:"Positive integer, dimensionality of the output space.",activation:"Activation function to use. Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. linear activation: a(x) = x).",use_bias:"Boolean, whether the layer uses a bias vector.",kernel_initializer:"Initializer for the kernel weights matrix, used for the linear transformation of the inputs.",recurrent_initializer:"Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.",bias_initializer:"Initializer for the bias vector.",kernel_regularizer:"Regularizer function applied to the kernel weights matrix.",recurrent_regularizer:"Regularizer function applied to the recurrent_kernel weights matrix.",bias_regularizer:"Regularizer function applied to the bias vector.",kernel_constraint:"Constraint function applied to the kernel weights matrix.",recurrent_constraint:"Constraint function applied to the recurrent_kernel weights matrix.",bias_constraint:"Constraint function applied to the bias vector.",dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.",recurrent_dropout:"Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state."},Softmax:{axis:"Integer, axis along which the softmax normalization is applied."},SpatialDropout1D:{rate:"float between 0 and 1.Fraction of the input units to drop."},SpatialDropout2D:{data_format:"'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension (the depth) is at index 1, in 'channels_last' mode is it at index 3. It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",rate:"float between 0 and 1.Fraction of the input units to drop."},SpatialDropout3D:{data_format:"'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension (the depth) is at index 1, in 'channels_last' mode is it at index 4. It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",rate:"float between 0 and 1.Fraction of the input units to drop."},ThresholdedReLU:{theta:"float &gt;= 0.Threshold location of activation."},TimeDistributed:{layer:"Recurrent instance.",merge_mode:"Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list."},UpSampling1D:{size:"integer.Upsampling factor."},UpSampling2D:{data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",interpolation:"A string, one of nearest or bilinear. Note that CNTK does not support yet the bilinear upscaling and that with Theano, only size=(2, 2) is possible.",size:"int, or tuple of 2 integers. The upsampling factors for rows and columns."},UpSampling3D:{data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",size:"int, or tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3."},ZeroPadding1D:{padding:"int, or tuple of int (length 2), or dictionary.</p>\n<ul>\n<li>If int:\n</ul>\n<p>How many zeros to add at the beginning and end of\nthe padding dimension (axis 1).</p>\n<ul>\n<li>If tuple of int (length 2):\n</ul>\n<p>How many zeros to add at the beginning and at the end of\nthe padding dimension ((left_pad, right_pad)).</p>\n"},ZeroPadding2D:{data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",padding:"int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.<ul>\n<li>If int: the same symmetric padding is applied to height and width.\n<li>If tuple of 2 ints: interpreted as two different symmetric padding values for height and width: (symmetric_height_pad, symmetric_width_pad).\n<li>If tuple of 2 tuples of 2 ints: interpreted as ((top_pad, bottom_pad), (left_pad, right_pad))\n</ul>\n"},ZeroPadding3D:{data_format:"A string, one of channels_last or channels_first . The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last .",padding:"int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.<ul>\n<li>If int: the same symmetric padding is applied to height and width.\n<li>If tuple of 3 ints: interpreted as two different symmetric padding values for height and width: (symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad).\n<li>If tuple of 3 tuples of 2 ints: interpreted as ((left_dim1_pad, right_dim1_pad),   (left_dim2_pad, right_dim2_pad),   (left_dim3_pad, right_dim3_pad))\n</ul>\n"},add:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (at least 2)."},average:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (at least 2)."},concatenate:{"**kwargs":"Standard layer keyword arguments.",axis:"Concatenation axis.",inputs:"A list of input tensors (at least 2)."},dot:{"**kwargs":"Standard layer keyword arguments.",axes:"Integer or tuple of integers, axis or axes along which to take the dot product.",inputs:"A list of input tensors (at least 2).",normalize:"Whether to L2-normalize samples along the dot product axis before taking the dot product. If set to True, then the output of the dot product is the cosine proximity between the two samples."},maximum:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (at least 2)."},multiply:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (at least 2)."},subtract:{"**kwargs":"Standard layer keyword arguments.",inputs:"A list of input tensors (exactly 2)."},activations:{elu:"",exponential:"",hard_sigmoid:"",linear:"",relu:"",selu:"",sigmoid:"",softmax:"",softplus:"",softsign:"",tanh:""},initializers:{constant:"",glorot_normal:"",glorot_uniform:"",he_normal:"",he_uniform:"",identity:"",lecun_normal:"",lecun_uniform:"",ones:"",orthogonal:"",random_normal:"",random_uniform:"",truncated_normal:"",uniform:"",zeros:""},constraints:{max_norm:"",maxnorm:"",min_max_norm:"",non_neg:"",nonneg:"",unit_norm:"",unitnorm:""},regularizer:{l1:"",l1_l2:"",l2:""}}},26:function(e,t,i){e.exports=i(60)},57:function(e,t,i){},60:function(e,t,i){"use strict";i.r(t);var n=i(0),a=i(12),r=i.n(a),o=i(7),s=i(8),l=i(10),u=i(9),h=i(11),c=i(6),d=i(2),p=function(e){function t(e){var i;return Object(o.a)(this,t),(i=Object(l.a)(this,Object(u.a)(t).call(this,e))).state={},i}return Object(h.a)(t,e),Object(s.a)(t,[{key:"render",value:function(){var e=this;return n.createElement(d.MDBBtn,{outline:!0,draggable:!0,onDragStart:function(t){t.dataTransfer.setData("storm-diagram-node",JSON.stringify(e.props.model))}},this.props.name)}}]),t}(n.Component),f=function(e){function t(e){var i;return Object(o.a)(this,t),(i=Object(l.a)(this,Object(u.a)(t).call(this,e))).state={},i}return Object(h.a)(t,e),Object(s.a)(t,[{key:"render",value:function(){for(var e={Core:["Dense","Activation","Dropout","Flatten","Input","Reshape","Permute","RepeatVector","Lambda","ActivityRegularization","Masking","SpatialDropout1D","SpatialDropout2D","SpatialDropout3D"],Convolutional:["Conv1D","Conv2D","Conv3D","SeparableConv1D","SeparableConv2D","DepthwiseConv2D","Conv2DTranspose","Conv3DTranspose","Cropping1D","Cropping2D","Cropping3D","UpSampling1D","UpSampling2D","UpSampling3D","ZeroPadding1D","ZeroPadding2D","ZeroPadding3D"],Pooling:["MaxPooling1D","MaxPooling2D","MaxPooling3D","AveragePooling1D","AveragePooling2D","AveragePooling3D","GlobalMaxPooling1D","GlobalMaxPooling2D","GlobalMaxPooling3D","GlobalAveragePooling1D","GlobalAveragePooling2D","GlobalAveragePooling3D"],"Locally-Connected":["LocallyConnected1D","LocallyConnected2D"],Recurrent:["RNN","SimpleRNN","SimpleRNNCell","GRU","GRUCell","LSTM","LSTMCell","ConvLSTM2D","CuDNNGRU","CuDNNLSTM"],Embedding:["Embedding"],Merge:["Add","Subtract","Multiply","Average","Maximum","Concatenate","Dot"],Activation:["LeakyReLU","PReLU","ReLU","ELU","ThresholdedReLU","Softmax"],Normalization:["BatchNormalization"],Noise:["GaussianNoise","GaussianDropout","AlphaDropout"]},t={Core:["danger","#ff4444"],Convolutional:["warning","#ffbb33"],Pooling:["success","#00C851"],"Locally-Connected":["info","#33b5e5"],Recurrent:["default","#2BBBAD"],Embedding:["primary","#4285F4"],Merge:["secondary","#aa66cc"],Activation:["elegant","#2E2E2E"],Normalization:["stylish","#4B515D"],Noise:["unique","#3F729B"]},i=Object.keys(e),a=[],r=0;r<i.length;r++){for(var o=i[r],s=t[o][1],l=e[o],u=[],h=0;h<l.length;h++)-1!==l[h].toLowerCase().indexOf(this.props.search.toLowerCase())&&(u.push(n.createElement(p,{model:{type:"inout",color:s,name:l[h]},name:l[h]})),u.push(n.createElement("br",null)));u.length>0&&a.push(n.createElement(d.MDBCard,{color:"unique-color-dark",border:"unique",style:{marginTop:"1rem"},className:"text-center"},n.createElement(d.MDBCardHeader,{color:"unique-color"},o," Layers"),n.createElement(d.MDBCardBody,null," ",u," ")))}return n.createElement("div",{className:"tray text-center"},a)}}]),t}(n.Component),g=i(13),m=i(23),_=i.n(m),b=i(24),v=i(25),w=i(15);i(53),i(55);Array.prototype.insert=function(e,t){this.splice(e,0,t)};var y=function(e){function t(e){var i;return Object(o.a)(this,t),(i=Object(l.a)(this,Object(u.a)(t).call(this,e))).state={search:"",diagramEngine:new g.DiagramEngine,selectedNode:void 0,exportModelType:"Caffe"},i.state.diagramEngine.installDefaultFactories(),i.handleClick=i.handleClick.bind(Object(c.a)(Object(c.a)(i))),i.handleSearch=i.handleSearch.bind(Object(c.a)(Object(c.a)(i))),i.handleChange=i.handleChange.bind(Object(c.a)(Object(c.a)(i))),i.handleModelSelect=i.handleModelSelect.bind(Object(c.a)(Object(c.a)(i))),i.getArgOptions=i.getArgOptions.bind(Object(c.a)(Object(c.a)(i))),i.toggle=i.toggle.bind(Object(c.a)(Object(c.a)(i))),i}return Object(h.a)(t,e),Object(s.a)(t,[{key:"compileGraph",value:function(){for(var e=this.state.diagramEngine.diagramModel.nodes,t=Object.keys(e),i=[],n=0;n<t.length;n++){var a=e[t[n]],r={name:a.name,args:a.args};i.push(r)}var o=this.state.diagramEngine.diagramModel.links,s=Object.keys(o),l=[];for(n=0;n<s.length;n++){var u,h;if(null!=o[s[n]].targetPort)"In"===o[s[n]].sourcePort.label?(u=o[s[n]].sourcePort.parent.id,h=o[s[n]].targetPort.parent.id):(u=o[s[n]].targetPort.parent.id,h=o[s[n]].sourcePort.parent.id),l.push([u,h])}return{nodes:t,nodeProps:i,edges:l,exportModelType:this.state.exportModelType}}},{key:"toggle",value:function(){this.setState({selectedNode:void 0})}},{key:"handleSearch",value:function(e){this.setState({search:e.target.value})}},{key:"handleClick",value:function(e){var t=document.getElementsByClassName("srd-node--selected");if(1===t.length&&void 0==this.state.selectedNode){var i=t[0].getAttribute("data-nodeid"),n=this.state.diagramEngine.diagramModel.nodes[i];this.setState({selectedNode:n})}}},{key:"handleChange",value:function(e){var t=this.state.selectedNode;t.args[e.target.name].value=e.target.value,this.setState({selectedNode:t})}},{key:"handleModelSelect",value:function(e){this.setState({exportModelType:e.target.name})}},{key:"getArgOptions",value:function(e){for(var t=Object.keys(w),i=!1,n=[],a=0;a<t.length;a++){var r=t[a];if(-1!==e.toLowerCase().indexOf(r)&&(n=Object.keys(w[r]),i=!0),i)break}return n}},{key:"render",value:function(){var e=this,t=[],i=!0;if(void 0!==this.state.selectedNode)for(var a=Object.keys(this.state.selectedNode.args),r=0;r<a.length;r++){var o,s=this.state.selectedNode.args[a[r]];Object.keys(w);if(s.required&&""==s.value&&(i=!1),s.options.length>0){for(var l=[],u=0;u<s.options.length;u++)l.push(n.createElement("option",{value:s.options[u]},s.options[u]));o=n.createElement("select",{validate:!0,name:a[r],value:s.value,onChange:this.handleChange,required:s.required},l)}else{var h="text";-1==s.description.indexOf("float")&&-1==s.description.indexOf("integer")&&-1==s.description.indexOf("number")||(h="number"),o=n.createElement("input",{validate:!0,type:h,name:a[r],value:s.value,onChange:this.handleChange,required:s.required})}t.push(n.createElement("div",null,n.createElement(d.MDBTooltip,{placement:"bottom",tooltipContent:s.description},a[r]," : ",o," ",n.createElement("br",null))))}return n.createElement("div",{onClick:this.handleClick},n.createElement(d.Navbar,{color:"unique-color-dark"},n.createElement(d.NavbarBrand,null,n.createElement("strong",{className:"white-text"},"NeuroSketch")),n.createElement(d.NavbarNav,{left:!0},n.createElement(d.NavItem,null,n.createElement(d.FormInline,{waves:!0},n.createElement("div",{className:"md-form my-0"},n.createElement("input",{className:"form-control mr-sm-2",placeholder:"Search",value:this.state.search,type:"text",onChange:this.handleSearch}))))),n.createElement(d.NavbarNav,{right:!0},n.createElement(d.NavItem,null,n.createElement(d.MDBBtn,{outline:!0,onClick:function(){_.a.ajax({url:"compile",type:"post",dataType:"json",data:JSON.stringify(e.compileGraph())})}},"Compile"),n.createElement(d.MDBDropdown,null,n.createElement(d.MDBDropdownToggle,{outline:!0,caret:!0,color:"default",onChange:this.handleModelSelect},this.state.exportModelType),n.createElement(d.MDBDropdownMenu,{basic:!0},n.createElement(d.MDBDropdownItem,{name:"Tensorflow",onClick:this.handleModelSelect},"Tensorflow"),n.createElement(d.MDBDropdownItem,{name:"CNTK",onClick:this.handleModelSelect},"CNTK"),n.createElement(d.MDBDropdownItem,{name:"Keras",onClick:this.handleModelSelect},"Keras"),n.createElement(d.MDBDropdownItem,{name:"Caffe",onClick:this.handleModelSelect},"Caffe"),n.createElement(d.MDBDropdownItem,{name:"PyTorch",onClick:this.handleModelSelect},"PyTorch"),n.createElement(d.MDBDropdownItem,{name:"MXNet",onClick:this.handleModelSelect},"MXNet"),n.createElement(d.MDBDropdownItem,{name:"CoreML",onClick:this.handleModelSelect},"CoreML")))))),n.createElement("div",{className:"body"},n.createElement("div",{className:"content"},n.createElement(f,{search:this.state.search}),n.createElement("div",{className:"diagram-layer",onDrop:function(t){var i=JSON.parse(t.dataTransfer.getData("storm-diagram-node")),n=new g.DefaultNodeModel(i.name,i.color);"in"===i.type?n.addInPort("In"):"out"===i.type?n.addOutPort("Out"):(n.addInPort("In"),n.addOutPort("Out"));var a=e.state.diagramEngine.getRelativeMousePoint(t),r=v[i.name],o=b[i.name],s=Object.keys(o);n.args={};for(var l=0;l<s.length;l++){var u=s[l],h=r[u],c=o[u],d=""==c,p=e.getArgOptions(h);"None"==c&&(p.length>0?p.insert(0,c):c=""),n.args[u]={description:h,required:d,value:c,options:p}}n.x=a.x,n.y=a.y,e.state.diagramEngine.getDiagramModel().addNode(n),e.setState({selectedNode:n}),e.forceUpdate()},onDragOver:function(e){e.preventDefault()}},n.createElement(g.DiagramWidget,{className:"srd-demo-canvas",diagramEngine:this.state.diagramEngine})))),n.createElement(d.Modal,{isOpen:void 0!==this.state.selectedNode,toggle:function(){i&&e.toggle()},fullHeight:!0,position:"right"},n.createElement(d.MDBRow,null,n.createElement(d.MDBCol,{md:"12"},n.createElement(d.MDBCard,null,n.createElement(d.MDBCardBody,null,n.createElement("form",null,n.createElement("div",{className:"grey-text"},t))),n.createElement(d.MDBModalFooter,null,n.createElement(d.MDBBtn,{className:"mb-6",disabled:!i,onClick:this.toggle}," Save ")))))))}}]),t}(n.Component);i(57);r.a.render(n.createElement(y,null),document.getElementById("root"))}},[[26,2,1]]]);
//# sourceMappingURL=main.09993df8.chunk.js.map