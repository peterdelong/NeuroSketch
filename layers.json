{
    "Activation": {
        "activation": "name of activation function to use\n    (see: <a href=\"../../activations/\">activations</a>),\n    or alternatively, a Theano or TensorFlow operation.</li>"
    },
    "ActivityRegularization": {
        "l1": "L1 regularization factor (positive float).</li>",
        "l2": "L2 regularization factor (positive float).</li>"
    },
    "AlphaDropout": {
        "rate": "float, drop probability (as with <code>Dropout</code>).\n    The multiplicative noise will have\n    standard deviation <code>sqrt(rate / (1 - rate))</code>.</li>",
        "seed": "A Python integer to use as random seed.</li>"
    },
    "AveragePooling1D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, steps, features)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, features, steps)</code>.</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pool_size": "Integer, size of the average pooling windows.</li>",
        "strides": "Integer, or None. Factor by which to downscale.\n    E.g. 2 will halve the input.\n    If None, it will default to <code>pool_size</code>.</li>"
    },
    "AveragePooling2D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pool_size": "integer or tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    (2, 2) will halve the input in both spatial dimension.\n    If only one integer is specified, the same window length\n    will be used for both dimensions.</li>",
        "strides": "Integer, tuple of 2 integers, or None.\n    Strides values.\n    If None, it will default to <code>pool_size</code>.</li>"
    },
    "AveragePooling3D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>channels_first</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pool_size": "tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    (2, 2, 2) will halve the size of the 3D input in each dimension.</li>",
        "strides": "tuple of 3 integers, or None. Strides values.</li>"
    },
    "BatchNormalization": {
        "axis": "Integer, the axis that should be normalized\n    (typically the features axis).\n    For instance, after a <code>Conv2D</code> layer with\n    <code>data_format=\"channels_first\"</code>,\n    set <code>axis=1</code> in <code>BatchNormalization</code>.</li>",
        "beta_constraint": "Optional constraint for the beta weight.</li>",
        "beta_initializer": "Initializer for the beta weight.</li>",
        "beta_regularizer": "Optional regularizer for the beta weight.</li>",
        "center": "If True, add offset of <code>beta</code> to normalized tensor.\n    If False, <code>beta</code> is ignored.</li>",
        "epsilon": "Small float added to variance to avoid dividing by zero.</li>",
        "gamma_constraint": "Optional constraint for the gamma weight.</li>",
        "gamma_initializer": "Initializer for the gamma weight.</li>",
        "gamma_regularizer": "Optional regularizer for the gamma weight.</li>",
        "momentum": "Momentum for the moving mean and the moving variance.</li>",
        "moving_mean_initializer": "Initializer for the moving mean.</li>",
        "moving_variance_initializer": "Initializer for the moving variance.</li>",
        "scale": "If True, multiply by <code>gamma</code>.\n    If False, <code>gamma</code> is not used.\n    When the next layer is linear (also e.g. <code>nn.relu</code>),\n    this can be disabled since the scaling\n    will be done by the next layer.</li>"
    },
    "Bidirectional": {
        "layer": "<code>Recurrent</code> instance.</li>",
        "merge_mode": "Mode by which outputs of the\n    forward and backward RNNs will be combined.\n    One of {'sum', 'mul', 'concat', 'ave', None}.\n    If None, the outputs will not be combined,\n    they will be returned as a list.</li>"
    },
    "Concatenate": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "Conv1D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> (default) or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, steps, channels)</code>\n    (default format for temporal data in Keras)\n    while <code>\"channels_first\"</code> corresponds to inputs\n    with shape <code>(batch, channels, steps)</code>.</li>",
        "dilation_rate": "an integer or tuple/list of a single integer, specifying\n    the dilation rate to use for dilated convolution.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any <code>strides</code> value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of a single integer,\n    specifying the length of the 1D convolution window.</li>",
        "padding": "One of <code>\"valid\"</code>, <code>\"causal\"</code> or <code>\"same\"</code> (case-insensitive).\n    <code>\"valid\"</code> means \"no padding\".\n    <code>\"same\"</code> results in padding the input such that\n    the output has the same length as the original input.\n    <code>\"causal\"</code> results in causal (dilated) convolutions,\n    e.g. <code>output[t]</code> does not depend on <code>input[t + 1:]</code>.\n    A zero padding is used such that\n    the output has the same length as the original input.\n    Useful when modeling temporal data where the model\n    should not violate the temporal order. See\n    <a href=\"https://arxiv.org/abs/1609.03499\">WaveNet: A Generative Model for Raw Audio, section 2.1</a>.</li>",
        "strides": "An integer or tuple/list of a single integer,\n    specifying the stride length of the convolution.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Conv2D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "dilation_rate": "an integer or tuple/list of 2 integers, specifying\n    the dilation rate to use for dilated convolution.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any stride value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of 2 integers, specifying the\n    height and width of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).\n    Note that <code>\"same\"</code> is slightly inconsistent across backends with\n    <code>strides</code> != 1, as described\n    <a href=\"https://github.com/keras-team/keras/pull/9473#issuecomment-372166860\">here</a></li>",
        "strides": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution\n    along the height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Conv2DTranspose": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "dilation_rate": "an integer or tuple/list of 2 integers, specifying\n    the dilation rate to use for dilated convolution.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any stride value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of 2 integers, specifying the\n    height and width of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "output_padding": "An integer or tuple/list of 2 integers,\n    specifying the amount of padding along the height and width\n    of the output tensor.\n    Can be a single integer to specify the same value for all\n    spatial dimensions.\n    The amount of output padding along a given dimension must be\n    lower than the stride along that same dimension.\n    If set to <code>None</code> (default), the output shape is inferred.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "strides": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution\n    along the height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Conv3D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>\"channels_first\"</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "dilation_rate": "an integer or tuple/list of 3 integers, specifying\n    the dilation rate to use for dilated convolution.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any stride value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of 3 integers, specifying the\n    depth, height and width of the 3D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "strides": "An integer or tuple/list of 3 integers,\n    specifying the strides of the convolution along each spatial dimension.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Conv3DTranspose": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, depth, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, depth, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "dilation_rate": "an integer or tuple/list of 3 integers, specifying\n    the dilation rate to use for dilated convolution.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any stride value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of 3 integers, specifying the\n    depth, height and width of the 3D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "output_padding": "An integer or tuple/list of 3 integers,\n    specifying the amount of padding along the depth, height, and\n    width.\n    Can be a single integer to specify the same value for all\n    spatial dimensions.\n    The amount of output padding along a given dimension must be\n    lower than the stride along that same dimension.\n    If set to <code>None</code> (default), the output shape is inferred.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "strides": "An integer or tuple/list of 3 integers,\n    specifying the strides of the convolution\n    along the depth, height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "ConvLSTM2D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> (default) or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, time, ..., channels)</code>\n    while <code>\"channels_first\"</code> corresponds to\n    inputs with shape <code>(batch, time, channels, ...)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be <code>\"channels_last\"</code>.</li>",
        "dilation_rate": "An integer or tuple/list of n integers, specifying\n    the dilation rate to use for dilated convolution.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any <code>strides</code> value != 1.</li>",
        "dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the inputs.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number output of filters in the convolution).</li>",
        "go_backwards": "Boolean (default False).\n    If True, process the input sequence backwards.</li>",
        "kernel_constraint": "Constraint function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix,\n    used for the linear transformation of the inputs.\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of n integers, specifying the\n    dimensions of the convolution window.</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "recurrent_activation": "Activation function to use\n    for the recurrent step\n    (see <a href=\"../../activations/\">activations</a>).</li>",
        "recurrent_constraint": "Constraint function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "recurrent_dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the recurrent state.</li>",
        "recurrent_initializer": "Initializer for the <code>recurrent_kernel</code>\n    weights matrix,\n    used for the linear transformation of the recurrent state.\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "recurrent_regularizer": "Regularizer function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "return_sequences": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.</li>",
        "stateful": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.</li>",
        "strides": "An integer or tuple/list of n integers,\n    specifying the strides of the convolution.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "unit_forget_bias": "Boolean.\n    If True, add 1 to the bias of the forget gate at initialization.\n    Use in combination with <code>bias_initializer=\"zeros\"</code>.\n    This is recommended in <a href=\"http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf\">Jozefowicz et al. (2015)</a>.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Cropping1D": {
        "cropping": "int or tuple of int (length 2)\n    How many units should be trimmed off at the beginning and end of\n    the cropping dimension (axis 1).\n    If a single int is provided,\n    the same value will be used for both.</li>"
    },
    "Cropping2D": {
        "cropping": "int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.<ul>\n<li>If int: the same symmetric cropping\n    is applied to height and width.</li>\n<li>If tuple of 2 ints:\n    interpreted as two different\n    symmetric cropping values for height and width:\n    <code>(symmetric_height_crop, symmetric_width_crop)</code>.</li>\n<li>If tuple of 2 tuples of 2 ints:\n    interpreted as\n    <code>((top_crop, bottom_crop), (left_crop, right_crop))</code></li>\n</ul>\n</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "Cropping3D": {
        "cropping": "int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.<ul>\n<li>If int: the same symmetric cropping\n    is applied to depth, height, and width.</li>\n<li>If tuple of 3 ints:\n    interpreted as two different\n    symmetric cropping values for depth, height, and width:\n    <code>(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)</code>.</li>\n<li>If tuple of 3 tuples of 2 ints:\n    interpreted as\n    <code>((left_dim1_crop, right_dim1_crop),\n      (left_dim2_crop, right_dim2_crop),\n      (left_dim3_crop, right_dim3_crop))</code></li>\n</ul>\n</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>\"channels_first\"</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "Dense": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_constraint": "Constraint function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "units": "Positive integer, dimensionality of the output space.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "DepthwiseConv2D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. 'linear' activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its 'activation').\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be 'channels_last'.</li>",
        "depth_multiplier": "The number of depthwise convolution output channels\n    for each input channel.\n    The total number of depthwise convolution output\n    channels will be equal to <code>filters_in * depth_multiplier</code>.</li>",
        "depthwise_constraint": "Constraint function applied to\n    the depthwise kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "depthwise_initializer": "Initializer for the depthwise kernel matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "depthwise_regularizer": "Regularizer function applied to\n    the depthwise kernel matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of 2 integers, specifying the\n    height and width of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "strides": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution\n    along the height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Dot": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "Dropout": {
        "noise_shape": "1D integer tensor representing the shape of the\n    binary dropout mask that will be multiplied with the input.\n    For instance, if your inputs have shape\n    <code>(batch_size, timesteps, features)</code> and\n    you want the dropout mask to be the same for all timesteps,\n    you can use <code>noise_shape=(batch_size, 1, features)</code>.</li>",
        "rate": "float between 0 and 1. Fraction of the input units to drop.</li>",
        "seed": "A Python integer to use as random seed.</li>"
    },
    "ELU": {
        "alpha": "scale for the negative factor.</li>"
    },
    "Embedding": {
        "embeddings_constraint": "Constraint function applied to\n    the <code>embeddings</code> matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "embeddings_initializer": "Initializer for the <code>embeddings</code> matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "embeddings_regularizer": "Regularizer function applied to\n    the <code>embeddings</code> matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "input_dim": "int &gt; 0. Size of the vocabulary,\n    i.e. maximum integer index + 1.</li>",
        "input_length": "Length of input sequences, when it is constant.\n    This argument is required if you are going to connect\n    <code>Flatten</code> then <code>Dense</code> layers upstream\n    (without it, the shape of the dense outputs cannot be computed).</li>",
        "mask_zero": "Whether or not the input value 0 is a special \"padding\"\n    value that should be masked out.\n    This is useful when using <a href=\"../recurrent/\">recurrent layers</a>\n    which may take variable length input.\n    If this is <code>True</code> then all subsequent layers\n    in the model need to support masking or an exception will be raised.\n    If mask_zero is set to True, as a consequence, index 0 cannot be\n    used in the vocabulary (input_dim should equal size of\n    vocabulary + 1).</li>",
        "output_dim": "int &gt;= 0. Dimension of the dense embedding.</li>"
    },
    "Flatten": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    The purpose of this argument is to preserve weight\n    ordering when switching a model from one data format\n    to another.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, ..., channels)</code> while <code>channels_first</code> corresponds to\n    inputs with shape <code>(batch, channels, ...)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "GRU": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    Default: hyperbolic tangent (<code>tanh</code>).\n    If you pass <code>None</code>, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the inputs.</li>",
        "go_backwards": "Boolean (default False).\n    If True, process the input sequence backwards and return the\n    reversed sequence.</li>",
        "implementation": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications.</li>",
        "kernel_constraint": "Constraint function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix,\n    used for the linear transformation of the inputs\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "recurrent_activation": "Activation function to use\n    for the recurrent step\n    (see <a href=\"../../activations/\">activations</a>).\n    Default: hard sigmoid (<code>hard_sigmoid</code>).\n    If you pass <code>None</code>, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "recurrent_constraint": "Constraint function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "recurrent_dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the recurrent state.</li>",
        "recurrent_initializer": "Initializer for the <code>recurrent_kernel</code>\n    weights matrix,\n    used for the linear transformation of the recurrent state\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "recurrent_regularizer": "Regularizer function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "reset_after": "GRU convention (whether to apply reset gate after or\n    before matrix multiplication). False = \"before\" (default),\n    True = \"after\" (CuDNN compatible).</li>",
        "return_sequences": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.</li>",
        "return_state": "Boolean. Whether to return the last state\n    in addition to the output.</li>",
        "stateful": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.</li>",
        "units": "Positive integer, dimensionality of the output space.</li>",
        "unroll": "Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "GaussianDropout": {
        "rate": "float, drop probability (as with <code>Dropout</code>).\n    The multiplicative noise will have\n    standard deviation <code>sqrt(rate / (1 - rate))</code>.</li>"
    },
    "GaussianNoise": {
        "stddev": "float, standard deviation of the noise distribution.</li>"
    },
    "GlobalAveragePooling1D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, steps, features)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, features, steps)</code>.</li>"
    },
    "GlobalAveragePooling2D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "GlobalAveragePooling3D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>channels_first</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "GlobalMaxPooling1D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, steps, features)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, features, steps)</code>.</li>"
    },
    "GlobalMaxPooling2D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "GlobalMaxPooling3D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>channels_first</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>"
    },
    "Input": {
        "batch_shape": "A shape tuple (integer), including the batch size.\n    For instance, <code>batch_shape=(10, 32)</code> indicates that\n    the expected input will be batches of 10 32-dimensional vectors.\n    <code>batch_shape=(None, 32)</code> indicates batches of an arbitrary number\n    of 32-dimensional vectors.</li>",
        "dtype": "The data type expected by the input, as a string\n    (<code>float32</code>, <code>float64</code>, <code>int32</code>...)</li>",
        "name": "An optional name string for the layer.\n    Should be unique in a model (do not reuse the same name twice).\n    It will be autogenerated if it isn't provided.</li>",
        "shape": "A shape tuple (integer), not including the batch size.\n    For instance, <code>shape=(32,)</code> indicates that the expected input\n    will be batches of 32-dimensional vectors.</li>",
        "sparse": "A boolean specifying whether the placeholder\n    to be created is sparse.</li>",
        "tensor": "Optional existing tensor to wrap into the <code>Input</code> layer.\n    If set, the layer will not create a placeholder tensor.</li>"
    },
    "LSTM": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    Default: hyperbolic tangent (<code>tanh</code>).\n    If you pass <code>None</code>, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the inputs.</li>",
        "go_backwards": "Boolean (default False).\n    If True, process the input sequence backwards and return the\n    reversed sequence.</li>",
        "implementation": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications.</li>",
        "kernel_constraint": "Constraint function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix,\n    used for the linear transformation of the inputs.\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "recurrent_activation": "Activation function to use\n    for the recurrent step\n    (see <a href=\"../../activations/\">activations</a>).\n    Default: hard sigmoid (<code>hard_sigmoid</code>).\n    If you pass <code>None</code>, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "recurrent_constraint": "Constraint function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "recurrent_dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the recurrent state.</li>",
        "recurrent_initializer": "Initializer for the <code>recurrent_kernel</code>\n    weights matrix,\n    used for the linear transformation of the recurrent state.\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "recurrent_regularizer": "Regularizer function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "return_sequences": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.</li>",
        "return_state": "Boolean. Whether to return the last state\n    in addition to the output.</li>",
        "stateful": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.</li>",
        "unit_forget_bias": "Boolean.\n    If True, add 1 to the bias of the forget gate at initialization.\n    Setting it to true will also force <code>bias_initializer=\"zeros\"</code>.\n    This is recommended in <a href=\"http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf\">Jozefowicz et al. (2015)</a>.</li>",
        "units": "Positive integer, dimensionality of the output space.</li>",
        "unroll": "Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "Lambda": {
        "arguments": "optional dictionary of keyword arguments to be passed\n    to the function.</li>",
        "function": "The function to be evaluated.\n    Takes input tensor or list of tensors as first argument.</li>",
        "output_shape": "Expected output shape from function.\n    Only relevant when using Theano.\n    Can be a tuple or function.\n    If a tuple, it only specifies the first dimension onward;\n         sample dimension is assumed either the same as the input:\n         <code>output_shape = (input_shape[0], ) + output_shape</code>\n         or, the input is <code>None</code> and\n         the sample dimension is also <code>None</code>:\n         <code>output_shape = (None, ) + output_shape</code>\n    If a function, it specifies the entire shape as a function of the\n    input shape: <code>output_shape = f(input_shape)</code></li>"
    },
    "LeakyReLU": {
        "alpha": "float &gt;= 0. Negative slope coefficient.</li>"
    },
    "LocallyConnected1D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of a single integer,\n    specifying the length of the 1D convolution window.</li>",
        "padding": "Currently only supports <code>\"valid\"</code> (case-insensitive).\n    <code>\"same\"</code> may be supported in the future.</li>",
        "strides": "An integer or tuple/list of a single integer,\n    specifying the stride length of the convolution.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "LocallyConnected2D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_constraint": "Constraint function applied to the kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "kernel_size": "An integer or tuple/list of 2 integers, specifying the\n    width and height of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "padding": "Currently only support <code>\"valid\"</code> (case-insensitive).\n    <code>\"same\"</code> will be supported in future.</li>",
        "strides": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution along the width and height.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "MaxPooling1D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, steps, features)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, features, steps)</code>.</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pool_size": "Integer, size of the max pooling windows.</li>",
        "strides": "Integer, or None. Factor by which to downscale.\n    E.g. 2 will halve the input.\n    If None, it will default to <code>pool_size</code>.</li>"
    },
    "MaxPooling2D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>channels_first</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pool_size": "integer or tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    (2, 2) will halve the input in both spatial dimension.\n    If only one integer is specified, the same window length\n    will be used for both dimensions.</li>",
        "strides": "Integer, tuple of 2 integers, or None.\n    Strides values.\n    If None, it will default to <code>pool_size</code>.</li>"
    },
    "MaxPooling3D": {
        "data_format": "A string,\n    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n    The ordering of the dimensions in the inputs.\n    <code>channels_last</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>channels_first</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "padding": "One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pool_size": "tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    (2, 2, 2) will halve the size of the 3D input in each dimension.</li>",
        "strides": "tuple of 3 integers, or None. Strides values.</li>"
    },
    "PReLU": {
        "alpha_constraint": "constraint for the weights.</li>",
        "alpha_initializer": "initializer function for the weights.</li>",
        "alpha_regularizer": "regularizer for the weights.</li>",
        "shared_axes": "the axes along which to share learnable\n    parameters for the activation function.\n    For example, if the incoming feature maps\n    are from a 2D convolution\n    with output shape <code>(batch, height, width, channels)</code>,\n    and you wish to share parameters across space\n    so that each filter only has one set of parameters,\n    set <code>shared_axes=[1, 2]</code>.</li>"
    },
    "Permute": {
        "dims": "Tuple of integers. Permutation pattern, does not include the\n    samples dimension. Indexing starts at 1.\n    For instance, <code>(2, 1)</code> permutes the first and second dimension\n    of the input.</li>"
    },
    "ReLU": {
    	"max_value": "float >= 0. Maximum activation value. negative_slope: float >= 0. Negative slope coefficient. threshold: float. Threshold value for thresholded activation."
    },
    "RNN": {
        "cell": "A RNN cell instance. A RNN cell is a class that has:</p>\n<ul>\n<li>a <code>call(input_at_t, states_at_t)</code> method, returning\n    <code>(output_at_t, states_at_t_plus_1)</code>. The call method of the\n    cell can also take the optional argument <code>constants</code>, see\n    section \"Note on passing external constants\" below.</li>\n<li>a <code>state_size</code> attribute. This can be a single integer\n    (single state) in which case it is\n    the size of the recurrent state\n    (which should be the same as the size of the cell output).\n    This can also be a list/tuple of integers\n    (one size per state).</li>\n<li>a <code>output_size</code> attribute. This can be a single integer or a\n    TensorShape, which represent the shape of the output. For\n    backward compatible reason, if this attribute is not available\n    for the cell, the value will be inferred by the first element\n    of the <code>state_size</code>.</li>\n</ul>\n<p>It is also possible for <code>cell</code> to be a list of RNN cell instances,\nin which cases the cells get stacked on after the other in the RNN,\nimplementing an efficient stacked RNN.</p>\n</li>",
        "go_backwards": "Boolean (default False).\n    If True, process the input sequence backwards and return the\n    reversed sequence.</li>",
        "input_dim": "dimensionality of the input (integer).\n    This argument (or alternatively,\n    the keyword argument <code>input_shape</code>)\n    is required when using this layer as the first layer in a model.</li>",
        "input_length": "Length of input sequences, to be specified\n    when it is constant.\n    This argument is required if you are going to connect\n    <code>Flatten</code> then <code>Dense</code> layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n    Note that if the recurrent layer is not the first layer\n    in your model, you would need to specify the input length\n    at the level of the first layer\n    (e.g. via the <code>input_shape</code> argument)</li>",
        "return_sequences": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.</p>\n</li>",
        "return_state": "Boolean. Whether to return the last state\n    in addition to the output.</li>",
        "stateful": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.</li>",
        "unroll": "Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.</li>"
    },
    "RepeatVector": {
        "n": "integer, repetition factor.</li>"
    },
    "Reshape": {
        "target_shape": "target shape. Tuple of integers.\n    Does not include the batch axis.</li>"
    },
    "SeparableConv1D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, steps, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, steps)</code>.</li>",
        "depth_multiplier": "The number of depthwise convolution output channels\n    for each input channel.\n    The total number of depthwise convolution output\n    channels will be equal to <code>filters_in * depth_multiplier</code>.</li>",
        "depthwise_constraint": "Constraint function applied to\n    the depthwise kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "depthwise_initializer": "Initializer for the depthwise kernel matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "depthwise_regularizer": "Regularizer function applied to\n    the depthwise kernel matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "dilation_rate": "An integer or tuple/list of a single integer, specifying\n    the dilation rate to use for dilated convolution.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any <code>strides</code> value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_size": "An integer or tuple/list of single integer,\n    specifying the length of the 1D convolution window.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pointwise_constraint": "Constraint function applied to\n    the pointwise kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "pointwise_initializer": "Initializer for the pointwise kernel matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "pointwise_regularizer": "Regularizer function applied to\n    the pointwise kernel matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "strides": "An integer or tuple/list of single integer,\n    specifying the stride length of the convolution.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "SeparableConv2D": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    If you don't specify anything, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "depth_multiplier": "The number of depthwise convolution output channels\n    for each input channel.\n    The total number of depthwise convolution output\n    channels will be equal to <code>filters_in * depth_multiplier</code>.</li>",
        "depthwise_constraint": "Constraint function applied to\n    the depthwise kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "depthwise_initializer": "Initializer for the depthwise kernel matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "depthwise_regularizer": "Regularizer function applied to\n    the depthwise kernel matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "dilation_rate": "An integer or tuple/list of 2 integers, specifying\n    the dilation rate to use for dilated convolution.\n    Currently, specifying any <code>dilation_rate</code> value != 1 is\n    incompatible with specifying any <code>strides</code> value != 1.</li>",
        "filters": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).</li>",
        "kernel_size": "An integer or tuple/list of 2 integers, specifying the\n    height and width of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.</li>",
        "padding": "one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>",
        "pointwise_constraint": "Constraint function applied to\n    the pointwise kernel matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "pointwise_initializer": "Initializer for the pointwise kernel matrix\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "pointwise_regularizer": "Regularizer function applied to\n    the pointwise kernel matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "strides": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution\n    along the height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any <code>dilation_rate</code> value != 1.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "SimpleRNN": {
        "activation": "Activation function to use\n    (see <a href=\"../../activations/\">activations</a>).\n    Default: hyperbolic tangent (<code>tanh</code>).\n    If you pass <code>None</code>, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "activity_regularizer": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "bias_constraint": "Constraint function applied to the bias vector\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "bias_initializer": "Initializer for the bias vector\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "bias_regularizer": "Regularizer function applied to the bias vector\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the inputs.</li>",
        "go_backwards": "Boolean (default False).\n    If True, process the input sequence backwards and return the\n    reversed sequence.</li>",
        "implementation": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications.</li>",
        "kernel_constraint": "Constraint function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "kernel_initializer": "Initializer for the <code>kernel</code> weights matrix,\n    used for the linear transformation of the inputs\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "kernel_regularizer": "Regularizer function applied to\n    the <code>kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "recurrent_activation": "Activation function to use\n    for the recurrent step\n    (see <a href=\"../../activations/\">activations</a>).\n    Default: hard sigmoid (<code>hard_sigmoid</code>).\n    If you pass <code>None</code>, no activation is applied\n    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>",
        "recurrent_constraint": "Constraint function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../constraints/\">constraints</a>).</li>",
        "recurrent_dropout": "Float between 0 and 1.\n    Fraction of the units to drop for\n    the linear transformation of the recurrent state.</li>",
        "recurrent_initializer": "Initializer for the <code>recurrent_kernel</code>\n    weights matrix,\n    used for the linear transformation of the recurrent state\n    (see <a href=\"../../initializers/\">initializers</a>).</li>",
        "recurrent_regularizer": "Regularizer function applied to\n    the <code>recurrent_kernel</code> weights matrix\n    (see <a href=\"../../regularizers/\">regularizer</a>).</li>",
        "reset_after": "GRU convention (whether to apply reset gate after or\n    before matrix multiplication). False = \"before\" (default),\n    True = \"after\" (CuDNN compatible).</li>",
        "return_sequences": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence.</li>",
        "return_state": "Boolean. Whether to return the last state\n    in addition to the output.</li>",
        "stateful": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.</li>",
        "units": "Positive integer, dimensionality of the output space.</li>",
        "unroll": "Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.</li>",
        "use_bias": "Boolean, whether the layer uses a bias vector.</li>"
    },
    "SimpleRNNCell" : {

    },
    "Softmax" : {
        "axis": "Integer, axis along which the softmax normalization is applied."
    },
    "SpatialDropout1D": {
        "rate": "float between 0 and 1. Fraction of the input units to drop.</li>"
    },
    "SpatialDropout2D": {
        "data_format": "'channels_first' or 'channels_last'.\n    In 'channels_first' mode, the channels dimension\n    (the depth) is at index 1,\n    in 'channels_last' mode is it at index 3.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "rate": "float between 0 and 1. Fraction of the input units to drop.</li>"
    },
    "SpatialDropout3D": {
        "data_format": "'channels_first' or 'channels_last'.\n    In 'channels_first' mode, the channels dimension (the depth)\n    is at index 1, in 'channels_last' mode is it at index 4.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "rate": "float between 0 and 1. Fraction of the input units to drop.</li>"
    },
    "ThresholdedReLU": {
        "theta": "float &gt;= 0. Threshold location of activation.</li>"
    },
    "TimeDistributed": {
        "layer": "<code>Recurrent</code> instance.</li>",
        "merge_mode": "Mode by which outputs of the\n    forward and backward RNNs will be combined.\n    One of {'sum', 'mul', 'concat', 'ave', None}.\n    If None, the outputs will not be combined,\n    they will be returned as a list.</li>"
    },
    "UpSampling1D": {
        "size": "integer. Upsampling factor.</li>"
    },
    "UpSampling2D": {
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "interpolation": "A string, one of <code>nearest</code> or <code>bilinear</code>.\n    Note that CNTK does not support yet the <code>bilinear</code> upscaling\n    and that with Theano, only <code>size=(2, 2)</code> is possible.</li>",
        "size": "int, or tuple of 2 integers.\n    The upsampling factors for rows and columns.</li>"
    },
    "UpSampling3D": {
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>\"channels_first\"</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "size": "int, or tuple of 3 integers.\n    The upsampling factors for dim1, dim2 and dim3.</li>"
    },
    "ZeroPadding1D": {
        "padding": "int, or tuple of int (length 2), or dictionary.</p>\n<ul>\n<li>If int:</li>\n</ul>\n<p>How many zeros to add at the beginning and end of\nthe padding dimension (axis 1).</p>\n<ul>\n<li>If tuple of int (length 2):</li>\n</ul>\n<p>How many zeros to add at the beginning and at the end of\nthe padding dimension (<code>(left_pad, right_pad)</code>).</p>\n</li>"
    },
    "ZeroPadding2D": {
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, height, width, channels)</code> while <code>\"channels_first\"</code>\n    corresponds to inputs with shape\n    <code>(batch, channels, height, width)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "padding": "int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.<ul>\n<li>If int: the same symmetric padding\n    is applied to height and width.</li>\n<li>If tuple of 2 ints:\n    interpreted as two different\n    symmetric padding values for height and width:\n    <code>(symmetric_height_pad, symmetric_width_pad)</code>.</li>\n<li>If tuple of 2 tuples of 2 ints:\n    interpreted as\n    <code>((top_pad, bottom_pad), (left_pad, right_pad))</code></li>\n</ul>\n</li>"
    },
    "ZeroPadding3D": {
        "data_format": "A string,\n    one of <code>\"channels_last\"</code> or <code>\"channels_first\"</code>.\n    The ordering of the dimensions in the inputs.\n    <code>\"channels_last\"</code> corresponds to inputs with shape\n    <code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>\n    while <code>\"channels_first\"</code> corresponds to inputs with shape\n    <code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>.\n    It defaults to the <code>image_data_format</code> value found in your\n    Keras config file at <code>~/.keras/keras.json</code>.\n    If you never set it, then it will be \"channels_last\".</li>",
        "padding": "int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.<ul>\n<li>If int: the same symmetric padding\n    is applied to height and width.</li>\n<li>If tuple of 3 ints:\n    interpreted as two different\n    symmetric padding values for height and width:\n    <code>(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)</code>.</li>\n<li>If tuple of 3 tuples of 2 ints:\n    interpreted as\n    <code>((left_dim1_pad, right_dim1_pad),\n      (left_dim2_pad, right_dim2_pad),\n      (left_dim3_pad, right_dim3_pad))</code></li>\n</ul>\n</li>"
    },
    "add": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "average": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "concatenate": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "axis": "Concatenation axis.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "dot": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "axes": "Integer or tuple of integers,\n    axis or axes along which to take the dot product.</li>",
        "inputs": "A list of input tensors (at least 2).</li>",
        "normalize": "Whether to L2-normalize samples along the\n    dot product axis before taking the dot product.\n    If set to True, then the output of the dot product\n    is the cosine proximity between the two samples.</li>"
    },
    "maximum": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "multiply": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (at least 2).</li>"
    },
    "subtract": {
        "**kwargs": "Standard layer keyword arguments.</li>",
        "inputs": "A list of input tensors (exactly 2).</li>"
    }
}